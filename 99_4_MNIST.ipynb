{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJptKBxALl-u",
        "outputId": "79e7b93c-fdc3-4334-9c31-cbab564b9116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "# Importing all the libraries in\n",
        "import torch # Import pytorch\n",
        "import torch.nn as nn # For creating Neural Network Models\n",
        "import torch.nn.functional as F #\n",
        "import torch.optim as optim # Importing optimizer from pytorch library\n",
        "from torchvision import datasets, transforms # Importing datasets and transform function to run over the dataset\n",
        "!pip install torchsummary # Installing Torch summary to view the model summary\n",
        "from torchsummary import summary # Importing the summary function from the installed torchsummary library"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # checking if Cuda is available, it is available it returns True, else returns False\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\") # Assign Device to Cuda or CPU based on avaiablily\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00Owi1LBNY8L",
        "outputId": "961dcd5b-f392-4b5b-8089-6924a8fea775"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# current Batch size is set to 128, meaning the dataset will be split in different batches,\n",
        "# each batch will contain 128 datapoints or here images. \n",
        "batch_size = 128\n",
        "\n",
        "# Calling a Dataloader function that takes in the dataset, batchsize and shuffle.\n",
        "# Here the dataset is mnist and is loaded from the datasets function loaded from \n",
        "# torch vision library\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    # loading MNIST dataset to data directory, train is true therefore loading the\n",
        "    # dataset from the training directory, download is true indicating the data needs\n",
        "    # to be downloaded. Performing a Transformation Operation, here there are two operations\n",
        "    # ToTensor and Normalize and each is performed one after the other. ToTensor operation is \n",
        "    # used to convert it tensor and Normalize takes in mean and std of the dataset to normalize\n",
        "    # in the input image. shuffle indicates the data will be loaded randomly\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.RandomApply([transforms.CenterCrop(22), ], p=0.1),\n",
        "                        transforms.Resize((28, 28)),\n",
        "                        transforms.RandomRotation((-15., 15.), fill=0),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,)\n",
        "                        ) # these are the MNIST dataset mean and std values of dataset set\n",
        "                    ])),\n",
        "                    \n",
        "    batch_size=batch_size, shuffle=True)\n",
        "  # Performing the same operation to create the test data, therefore train is set to false and\n",
        "  # is loaded to test_loader\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,)) # these are the MNIST dataset mean and std values of training set\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "EQZaZRGcNLtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "372159f3-61e8-4971-af4d-0383dfdaf329"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 163837419.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 118993805.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 25600000.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 12394618.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Notes on our naive model\n",
        "\n",
        "We are going to write a network based on what we have learnt so far. \n",
        "\n",
        "The size of the input image is 28x28x1. We are going to add as many layers as required to reach RF = 32 \"atleast\". "
      ],
      "metadata": {
        "id": "r3gEjf-xMb-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    #This defines the structure of the NN.\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3,bias = False)\n",
        "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3,bias = False)\n",
        "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3,bias = False)\n",
        "        self.conv4 = nn.Conv2d(32, 16, kernel_size=1,bias = False)\n",
        "        self.conv5 = nn.Conv2d(16, 16, kernel_size=3,bias = False)\n",
        "        self.conv6 = nn.Conv2d(16, 16, kernel_size=3,bias = False)\n",
        "        self.conv7 = nn.Conv2d(16, 16, padding = 1, kernel_size=3,bias = False)\n",
        "        self.conv8 = nn.Conv2d(16, 16, kernel_size=3,bias = False)\n",
        "        self.conv9 = nn.Conv2d(16, 10, kernel_size=1,bias = False)\n",
        "        self.batch1 = nn.BatchNorm2d(16)\n",
        "        self.batch2 = nn.BatchNorm2d(16)\n",
        "        self.batch3 = nn.BatchNorm2d(32)\n",
        "        self.batch4 = nn.BatchNorm2d(16)\n",
        "        self.batch5 = nn.BatchNorm2d(16)\n",
        "        self.batch6 = nn.BatchNorm2d(16)\n",
        "        self.batch7 = nn.BatchNorm2d(16)\n",
        "        self.batch8 = nn.BatchNorm2d(16)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.dropout1 = nn.Dropout2d(0.1)\n",
        "        self.dropout2 = nn.Dropout2d(0.1)\n",
        "        self.dropout3 = nn.Dropout2d(0.1)\n",
        "        self.dropout4 = nn.Dropout2d(0.1)\n",
        "        self.dropout5 = nn.Dropout2d(0.1)\n",
        "        self.dropout6 = nn.Dropout2d(0.1)\n",
        "        self.dropout7 = nn.Dropout2d(0.1)\n",
        "        self.avgpool = nn.AvgPool2d(5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout1(self.batch1(F.relu(self.conv1(x))))\n",
        "        x = self.dropout2(self.batch2(F.relu(self.conv2(x))))\n",
        "        x = self.dropout3(self.batch3(F.relu(self.conv3(x))))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = self.dropout4(self.batch4(F.relu(self.conv5(x))))\n",
        "        x = self.dropout5(self.batch5(F.relu(self.conv6(x))))\n",
        "        x = self.dropout6(self.batch6(F.relu(self.conv7(x))))\n",
        "        x = self.dropout7(self.batch7(F.relu(self.conv8(x))))\n",
        "        x = self.avgpool(self.conv9(x))\n",
        "        x = x.view(-1,10)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# loading Neural Network to device\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "metadata": {
        "id": "Sir2LmSVLr_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "746fcb7d-c41d-4ce0-f42f-6c22eca24ead"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 26, 26]             144\n",
            "       BatchNorm2d-2           [-1, 16, 26, 26]              32\n",
            "         Dropout2d-3           [-1, 16, 26, 26]               0\n",
            "            Conv2d-4           [-1, 16, 24, 24]           2,304\n",
            "       BatchNorm2d-5           [-1, 16, 24, 24]              32\n",
            "         Dropout2d-6           [-1, 16, 24, 24]               0\n",
            "            Conv2d-7           [-1, 32, 22, 22]           4,608\n",
            "       BatchNorm2d-8           [-1, 32, 22, 22]              64\n",
            "         Dropout2d-9           [-1, 32, 22, 22]               0\n",
            "           Conv2d-10           [-1, 16, 22, 22]             512\n",
            "        MaxPool2d-11           [-1, 16, 11, 11]               0\n",
            "           Conv2d-12             [-1, 16, 9, 9]           2,304\n",
            "      BatchNorm2d-13             [-1, 16, 9, 9]              32\n",
            "        Dropout2d-14             [-1, 16, 9, 9]               0\n",
            "           Conv2d-15             [-1, 16, 7, 7]           2,304\n",
            "      BatchNorm2d-16             [-1, 16, 7, 7]              32\n",
            "        Dropout2d-17             [-1, 16, 7, 7]               0\n",
            "           Conv2d-18             [-1, 16, 7, 7]           2,304\n",
            "      BatchNorm2d-19             [-1, 16, 7, 7]              32\n",
            "        Dropout2d-20             [-1, 16, 7, 7]               0\n",
            "           Conv2d-21             [-1, 16, 5, 5]           2,304\n",
            "      BatchNorm2d-22             [-1, 16, 5, 5]              32\n",
            "        Dropout2d-23             [-1, 16, 5, 5]               0\n",
            "           Conv2d-24             [-1, 10, 5, 5]             160\n",
            "        AvgPool2d-25             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 17,200\n",
            "Trainable params: 17,200\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.96\n",
            "Params size (MB): 0.07\n",
            "Estimated Total Size (MB): 1.03\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "def train(model:nn.Module, device:torch.device, train_loader, optimizer, epoch):\n",
        "    # print(type(model))\n",
        "    # print(type(device))\n",
        "    # print(type(train_loader))\n",
        "    # print(type(optimizer))\n",
        "    # print(type(epoch))\n",
        "    # Putting the model to train mode\n",
        "    model.train()\n",
        "    \n",
        "    # Loading train dtaloader to Tqdm to produce output in bar for \n",
        "    # visual interpretation.\n",
        "    correct = 0\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        # adding data and target label to cuda\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        # print(\"\\nData Shape:\",data.shape)\n",
        "        # making all the gradients zero before forward propogation\n",
        "        optimizer.zero_grad()\n",
        "        # print(\"Target Shape:\",target.shape)\n",
        "        # loading data to model\n",
        "        output = model(data)\n",
        "        # print(\"output Shape:\",output.shape)\n",
        "        \n",
        "        # calculating loss with output and target using negative log likelyhood loss\n",
        "        loss = F.nll_loss(output, target)\n",
        "        \n",
        "        # calcualting back propogation\n",
        "        loss.backward()\n",
        "        \n",
        "        # Revaulating the model and updating the gradient\n",
        "        optimizer.step()\n",
        "        \n",
        "        pred = output.argmax(dim=1,keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx} Accuracy = {correct/len(train_loader.dataset)}')\n",
        "        # break\n",
        "    # print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "    #     test_loss, correct, len(test_loader.dataset),\n",
        "    #     100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    # Putting the model to eval mode\n",
        "    model.eval()\n",
        "\n",
        "    # Test_loss is kept to 0\n",
        "    test_loss = 0\n",
        "    \n",
        "    # correct value \n",
        "    correct = 0\n",
        "    # Loading model without gradient\n",
        "    with torch.no_grad():\n",
        "        # Load test model\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            # Running model to testing data\n",
        "            output = model(data)\n",
        "            # calculating testing call\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            # calculating prediction\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            # checking all the correct predictions\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "g_vlC-bdNzo1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Stochastic gradient descent optimzer with momentum with learning as 0.01 and momentum as 0.9.\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1, verbose=True)\n",
        "#running the model for one epoch \n",
        "for epoch in range(1, 21):\n",
        "    # calling the train the function that takes in model, device, \n",
        "    # train_loader, optimzer and epoch as input\n",
        "    print(\"Epoch:\",epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    # calling the test the function that takes in model, device, \n",
        "    # test_loader as input\n",
        "    test(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0FYVWkGOFBS",
        "outputId": "6b66a69f-b0f2-45e7-e29f-101b8b71d6e1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.12354777008295059 batch_id=468 Accuracy = 0.8275166666666667: 100%|██████████| 469/469 [00:33<00:00, 14.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0692, Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "Epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.13961510360240936 batch_id=468 Accuracy = 0.9527166666666667: 100%|██████████| 469/469 [00:31<00:00, 15.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0479, Accuracy: 9858/10000 (98.58%)\n",
            "\n",
            "Epoch: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.12682782113552094 batch_id=468 Accuracy = 0.96255: 100%|██████████| 469/469 [00:30<00:00, 15.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0335, Accuracy: 9906/10000 (99.06%)\n",
            "\n",
            "Epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.06745871156454086 batch_id=468 Accuracy = 0.9664166666666667: 100%|██████████| 469/469 [00:30<00:00, 15.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0301, Accuracy: 9919/10000 (99.19%)\n",
            "\n",
            "Epoch: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.2324662208557129 batch_id=468 Accuracy = 0.96935: 100%|██████████| 469/469 [00:30<00:00, 15.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0273, Accuracy: 9917/10000 (99.17%)\n",
            "\n",
            "Epoch: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.07950099557638168 batch_id=468 Accuracy = 0.9716166666666667: 100%|██████████| 469/469 [00:30<00:00, 15.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0289, Accuracy: 9904/10000 (99.04%)\n",
            "\n",
            "Epoch: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.09743116050958633 batch_id=468 Accuracy = 0.97285: 100%|██████████| 469/469 [00:29<00:00, 15.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0244, Accuracy: 9922/10000 (99.22%)\n",
            "\n",
            "Epoch: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.0546792633831501 batch_id=468 Accuracy = 0.9755: 100%|██████████| 469/469 [00:30<00:00, 15.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0253, Accuracy: 9917/10000 (99.17%)\n",
            "\n",
            "Epoch: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.12470967322587967 batch_id=468 Accuracy = 0.9755666666666667: 100%|██████████| 469/469 [00:30<00:00, 15.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0230, Accuracy: 9929/10000 (99.29%)\n",
            "\n",
            "Epoch: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.0580698698759079 batch_id=468 Accuracy = 0.9755833333333334: 100%|██████████| 469/469 [00:29<00:00, 15.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0225, Accuracy: 9930/10000 (99.30%)\n",
            "\n",
            "Epoch: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.07679096609354019 batch_id=468 Accuracy = 0.9776833333333333: 100%|██████████| 469/469 [00:30<00:00, 15.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0211, Accuracy: 9937/10000 (99.37%)\n",
            "\n",
            "Epoch: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.22441083192825317 batch_id=468 Accuracy = 0.9773333333333334: 100%|██████████| 469/469 [00:30<00:00, 15.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0213, Accuracy: 9934/10000 (99.34%)\n",
            "\n",
            "Epoch: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.15725980699062347 batch_id=468 Accuracy = 0.9785666666666667: 100%|██████████| 469/469 [00:29<00:00, 15.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0221, Accuracy: 9921/10000 (99.21%)\n",
            "\n",
            "Epoch: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.15376102924346924 batch_id=468 Accuracy = 0.9785333333333334: 100%|██████████| 469/469 [00:31<00:00, 14.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0192, Accuracy: 9937/10000 (99.37%)\n",
            "\n",
            "Epoch: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.16552381217479706 batch_id=468 Accuracy = 0.9795833333333334: 100%|██████████| 469/469 [00:31<00:00, 15.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0186, Accuracy: 9937/10000 (99.37%)\n",
            "\n",
            "Epoch: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.02699831686913967 batch_id=468 Accuracy = 0.9792833333333333: 100%|██████████| 469/469 [00:30<00:00, 15.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0202, Accuracy: 9938/10000 (99.38%)\n",
            "\n",
            "Epoch: 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.06324764341115952 batch_id=468 Accuracy = 0.9800166666666666: 100%|██████████| 469/469 [00:30<00:00, 15.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0199, Accuracy: 9944/10000 (99.44%)\n",
            "\n",
            "Epoch: 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.08698845654726028 batch_id=468 Accuracy = 0.9807833333333333: 100%|██████████| 469/469 [00:30<00:00, 15.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0201, Accuracy: 9933/10000 (99.33%)\n",
            "\n",
            "Epoch: 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.15648655593395233 batch_id=468 Accuracy = 0.9797: 100%|██████████| 469/469 [00:30<00:00, 15.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0184, Accuracy: 9943/10000 (99.43%)\n",
            "\n",
            "Epoch: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.014032346196472645 batch_id=468 Accuracy = 0.9799166666666667: 100%|██████████| 469/469 [00:30<00:00, 15.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0183, Accuracy: 9943/10000 (99.43%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With Scheduler\n"
      ],
      "metadata": {
        "id": "UoxvOodKx7vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Stochastic gradient descent optimzer with momentum with learning as 0.01 and momentum as 0.9.\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1, verbose=True)\n",
        "#running the model for one epoch \n",
        "for epoch in range(1, 21):\n",
        "    # calling the train the function that takes in model, device, \n",
        "    # train_loader, optimzer and epoch as input\n",
        "    print(\"Epoch:\",epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    # calling the test the function that takes in model, device, \n",
        "    # test_loader as input\n",
        "    test(model, device, test_loader)"
      ],
      "metadata": {
        "id": "OE-8gHBgevOS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b95da1a9-ca2a-4e19-8ce0-23f68ff9753c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 26, 26]             144\n",
            "       BatchNorm2d-2           [-1, 16, 26, 26]              32\n",
            "         Dropout2d-3           [-1, 16, 26, 26]               0\n",
            "            Conv2d-4           [-1, 16, 24, 24]           2,304\n",
            "       BatchNorm2d-5           [-1, 16, 24, 24]              32\n",
            "         Dropout2d-6           [-1, 16, 24, 24]               0\n",
            "            Conv2d-7           [-1, 32, 22, 22]           4,608\n",
            "       BatchNorm2d-8           [-1, 32, 22, 22]              64\n",
            "         Dropout2d-9           [-1, 32, 22, 22]               0\n",
            "           Conv2d-10           [-1, 16, 22, 22]             512\n",
            "        MaxPool2d-11           [-1, 16, 11, 11]               0\n",
            "           Conv2d-12             [-1, 16, 9, 9]           2,304\n",
            "      BatchNorm2d-13             [-1, 16, 9, 9]              32\n",
            "        Dropout2d-14             [-1, 16, 9, 9]               0\n",
            "           Conv2d-15             [-1, 16, 7, 7]           2,304\n",
            "      BatchNorm2d-16             [-1, 16, 7, 7]              32\n",
            "        Dropout2d-17             [-1, 16, 7, 7]               0\n",
            "           Conv2d-18             [-1, 16, 7, 7]           2,304\n",
            "      BatchNorm2d-19             [-1, 16, 7, 7]              32\n",
            "        Dropout2d-20             [-1, 16, 7, 7]               0\n",
            "           Conv2d-21             [-1, 16, 5, 5]           2,304\n",
            "      BatchNorm2d-22             [-1, 16, 5, 5]              32\n",
            "        Dropout2d-23             [-1, 16, 5, 5]               0\n",
            "           Conv2d-24             [-1, 10, 5, 5]             160\n",
            "        AvgPool2d-25             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 17,200\n",
            "Trainable params: 17,200\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.96\n",
            "Params size (MB): 0.07\n",
            "Estimated Total Size (MB): 1.03\n",
            "----------------------------------------------------------------\n",
            "Adjusting learning rate of group 0 to 1.0000e-02.\n",
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.14270387589931488 batch_id=468 Accuracy = 0.8207666666666666: 100%|██████████| 469/469 [00:31<00:00, 14.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0706, Accuracy: 9809/10000 (98.09%)\n",
            "\n",
            "Epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.13561177253723145 batch_id=468 Accuracy = 0.9539166666666666: 100%|██████████| 469/469 [00:30<00:00, 15.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0429, Accuracy: 9872/10000 (98.72%)\n",
            "\n",
            "Epoch: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.11224984377622604 batch_id=468 Accuracy = 0.9630833333333333: 100%|██████████| 469/469 [00:30<00:00, 15.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0334, Accuracy: 9898/10000 (98.98%)\n",
            "\n",
            "Epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.11910528689622879 batch_id=468 Accuracy = 0.9687666666666667: 100%|██████████| 469/469 [00:30<00:00, 15.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0280, Accuracy: 9910/10000 (99.10%)\n",
            "\n",
            "Epoch: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.08742427825927734 batch_id=468 Accuracy = 0.9704666666666667: 100%|██████████| 469/469 [00:30<00:00, 15.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0311, Accuracy: 9905/10000 (99.05%)\n",
            "\n",
            "Epoch: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.14327527582645416 batch_id=468 Accuracy = 0.97045: 100%|██████████| 469/469 [00:30<00:00, 15.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0278, Accuracy: 9914/10000 (99.14%)\n",
            "\n",
            "Epoch: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.1552935540676117 batch_id=468 Accuracy = 0.9731833333333333: 100%|██████████| 469/469 [00:30<00:00, 15.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0284, Accuracy: 9910/10000 (99.10%)\n",
            "\n",
            "Epoch: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.09453827142715454 batch_id=468 Accuracy = 0.9744166666666667: 100%|██████████| 469/469 [00:31<00:00, 15.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0246, Accuracy: 9925/10000 (99.25%)\n",
            "\n",
            "Epoch: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.041011519730091095 batch_id=468 Accuracy = 0.9742: 100%|██████████| 469/469 [00:30<00:00, 15.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0256, Accuracy: 9912/10000 (99.12%)\n",
            "\n",
            "Epoch: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.14996129274368286 batch_id=468 Accuracy = 0.9759166666666667: 100%|██████████| 469/469 [00:30<00:00, 15.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0248, Accuracy: 9927/10000 (99.27%)\n",
            "\n",
            "Epoch: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.02681819163262844 batch_id=468 Accuracy = 0.9765: 100%|██████████| 469/469 [00:31<00:00, 14.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0227, Accuracy: 9926/10000 (99.26%)\n",
            "\n",
            "Epoch: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.08092562854290009 batch_id=468 Accuracy = 0.977: 100%|██████████| 469/469 [00:31<00:00, 14.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0212, Accuracy: 9933/10000 (99.33%)\n",
            "\n",
            "Epoch: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.05091549828648567 batch_id=468 Accuracy = 0.9779666666666667: 100%|██████████| 469/469 [00:30<00:00, 15.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0201, Accuracy: 9940/10000 (99.40%)\n",
            "\n",
            "Epoch: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.08318787813186646 batch_id=468 Accuracy = 0.9781833333333333: 100%|██████████| 469/469 [00:30<00:00, 15.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0201, Accuracy: 9938/10000 (99.38%)\n",
            "\n",
            "Epoch: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.014820307493209839 batch_id=468 Accuracy = 0.97895: 100%|██████████| 469/469 [00:31<00:00, 15.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0205, Accuracy: 9933/10000 (99.33%)\n",
            "\n",
            "Epoch: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.08080179244279861 batch_id=468 Accuracy = 0.97935: 100%|██████████| 469/469 [00:30<00:00, 15.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0201, Accuracy: 9936/10000 (99.36%)\n",
            "\n",
            "Epoch: 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.13949298858642578 batch_id=468 Accuracy = 0.9783166666666666: 100%|██████████| 469/469 [00:30<00:00, 15.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0204, Accuracy: 9939/10000 (99.39%)\n",
            "\n",
            "Epoch: 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.02707289718091488 batch_id=468 Accuracy = 0.9795: 100%|██████████| 469/469 [00:30<00:00, 15.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0198, Accuracy: 9937/10000 (99.37%)\n",
            "\n",
            "Epoch: 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.11449801176786423 batch_id=468 Accuracy = 0.9804166666666667: 100%|██████████| 469/469 [00:30<00:00, 15.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0192, Accuracy: 9939/10000 (99.39%)\n",
            "\n",
            "Epoch: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.09861847013235092 batch_id=468 Accuracy = 0.9805833333333334: 100%|██████████| 469/469 [00:30<00:00, 15.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0204, Accuracy: 9934/10000 (99.34%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SGwc9E5q0prd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}